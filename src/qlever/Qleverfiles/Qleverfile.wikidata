# Qleverfile for Wikidata, use with https://github.com/ad-freiburg/qlever-control
#
# qlever get-data    downloads two .bz2 files of total size ~100 GB
# qlever index       takes ~7 hours and ~40 GB RAM (on an AMD Ryzen 9 5900X)
# qlever start       starts the server (takes around 30 seconds)

[data]
NAME         = wikidata
GET_DATA_URL = https://dumps.wikimedia.org/wikidatawiki/entities
GET_DATA_CMD = curl -LO -C - ${GET_DATA_URL}/latest-all.ttl.bz2 ${GET_DATA_URL}/latest-lexemes.ttl.bz2
DESCRIPTION  = "Full Wikidata dump from ${GET_DATA_URL} (latest-all.ttl.bz2 and latest-lexemes.ttl.bz2)"

[index]
INPUT_FILES     = latest-lexemes.ttl.bz2 latest-all.ttl.bz2 
CAT_INPUT_FILES = bzcat ${INPUT_FILES}
SETTINGS_JSON   = { "languages-internal": [], "prefixes-external": [""], "locale": { "language": "en", "country": "US", "ignore-punctuation": true }, "ascii-prefixes-only": false, "num-triples-per-batch": 5000000 }
STXXL_MEMORY    = 10G

[server]
PORT               = 7001
ACCESS_TOKEN       = ${data:NAME}_372483264
MEMORY_FOR_QUERIES = 20G
CACHE_MAX_SIZE     = 10G

[runtime]
SYSTEM = docker
IMAGE  = docker.io/adfreiburg/qlever:latest

[ui]
UI_CONFIG = wikidata
